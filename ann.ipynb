{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "img_x_size = int(335)\n",
    "img_y_size = int(218)\n",
    "num_channels = 1\n",
    "input_size = img_x_size * img_y_size * num_channels\n",
    "dropout_p = 0.4\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    device = torch.device('cpu')\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        fc1_in = input_size\n",
    "        fc1_out = 1000\n",
    "        self.fc1 = nn.Linear(fc1_in, fc1_out)\n",
    "        nn.init.normal_(self.fc1.weight, mean=0, std=1/math.sqrt(fc1_in))\n",
    "        nn.init.normal_(self.fc1.bias, mean=0, std=1)\n",
    "        # self.dropout1 = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(fc1_out) # Batch normalization for fc1\n",
    "        # TODO: weight initialization for batchnorm layer?\n",
    "\n",
    "        fc2_in = fc1_out\n",
    "        fc2_out = 500\n",
    "        self.fc2 = nn.Linear(fc2_in, fc2_out)\n",
    "        nn.init.normal_(self.fc2.weight, mean=0, std=1/math.sqrt(fc2_in))\n",
    "        nn.init.normal_(self.fc2.bias, mean=0, std=1)\n",
    "        # self.dropout2 = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(fc2_out)   # Batch normalization for fc2\n",
    "\n",
    "        fc3_in = fc2_out\n",
    "        fc3_out = 100\n",
    "        self.fc3 = nn.Linear(fc3_in, fc3_out)  # Output layer with 10 units for 10 genres\n",
    "        nn.init.normal_(self.fc3.weight, mean=0, std=1/math.sqrt(fc3_in))\n",
    "        nn.init.normal_(self.fc3.bias, mean=0, std=1)\n",
    "        # self.dropout3 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(fc3_out)   # Batch normalization for fc2\n",
    "\n",
    "        fc4_in = fc3_out\n",
    "        fc4_out = 10\n",
    "        self.fc4 = nn.Linear(fc4_in, fc4_out)  # Output layer with 10 units for 10 genres\n",
    "        nn.init.normal_(self.fc4.weight, mean=0, std=1/math.sqrt(fc4_in))\n",
    "        nn.init.normal_(self.fc4.bias, mean=0, std=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, input_size)\n",
    "\n",
    "        # Apply sigmoid activation at each layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)  # Apply batch normalization to fc1\n",
    "        # x = self.dropout1(x)  # Apply dropout after the first layer\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn2(x)  # Apply batch normalization to fc2\n",
    "        # x = self.dropout2(x)  # Apply dropout after the second layer\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.bn3(x)  # Apply batch normalization to fc2\n",
    "        # x = self.dropout3(x)  # Apply dropout after the second layer\n",
    "\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "        # x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape - Images: torch.Size([64, 1, 218, 335])\n",
      "Batch shape - Labels: torch.Size([64])\n",
      "Minimum pixel value: tensor(-1.)\n",
      "Maximum pixel value: tensor(0.9294)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def custom_transform(image):\n",
    "    # Crop the image to the desired region of interest (ROI)\n",
    "    image = image.crop((55, 35, 390, 253))\n",
    "    # Convert the cropped image to a PyTorch tensor\n",
    "    return transforms.ToTensor()(image)\n",
    "\n",
    "def load_data():\n",
    "    # Define your data transformation (without resizing)\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Lambda(custom_transform),  # Apply the custom transformation\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    class CustomImageDataset(datasets.ImageFolder):\n",
    "        def __init__(self, root, transform=None):\n",
    "            super(CustomImageDataset, self).__init__(root=root, transform=transform)\n",
    "\n",
    "    # Define the path to your data folder\n",
    "    data_dir = 'data/images_original'\n",
    "\n",
    "    # Create an instance of your custom dataset\n",
    "    custom_dataset = CustomImageDataset(root=data_dir, transform=data_transform)\n",
    "\n",
    "    # Calculate the size of the training and testing sets\n",
    "    total_size = len(custom_dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    test_size = total_size - train_size\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size])\n",
    "    batch_size = 64  # You can adjust this batch size as needed\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_data()\n",
    "\n",
    "# Get a batch of data from the training loader\n",
    "data_iterator = iter(train_loader)\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "# Check the shape of the batch\n",
    "print(\"Batch shape - Images:\", images.shape)\n",
    "print(\"Batch shape - Labels:\", labels.shape)\n",
    "\n",
    "# Access a single image from the batch (e.g., the first image)\n",
    "image = images[0]\n",
    "\n",
    "# Check the normalized pixel values\n",
    "print(\"Minimum pixel value:\", image.min())\n",
    "print(\"Maximum pixel value:\", image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10] Loss: 2.397\n",
      "Test Accuracy after 1 epochs: 22.00%\n",
      "[2, 10] Loss: 1.590\n",
      "Test Accuracy after 2 epochs: 31.50%\n",
      "[3, 10] Loss: 1.250\n",
      "Test Accuracy after 3 epochs: 37.50%\n",
      "[4, 10] Loss: 0.948\n",
      "Test Accuracy after 4 epochs: 38.50%\n",
      "[5, 10] Loss: 0.702\n",
      "Test Accuracy after 5 epochs: 42.00%\n",
      "[6, 10] Loss: 0.487\n",
      "Test Accuracy after 6 epochs: 43.50%\n",
      "[7, 10] Loss: 0.356\n",
      "Test Accuracy after 7 epochs: 43.00%\n",
      "[8, 10] Loss: 0.215\n",
      "Test Accuracy after 8 epochs: 45.00%\n",
      "[9, 10] Loss: 0.169\n",
      "Test Accuracy after 9 epochs: 47.50%\n",
      "[10, 10] Loss: 0.120\n",
      "Test Accuracy after 10 epochs: 46.50%\n",
      "[11, 10] Loss: 0.091\n",
      "Test Accuracy after 11 epochs: 46.00%\n",
      "[12, 10] Loss: 0.088\n",
      "Test Accuracy after 12 epochs: 45.00%\n",
      "[13, 10] Loss: 0.071\n",
      "Test Accuracy after 13 epochs: 43.00%\n",
      "[14, 10] Loss: 0.061\n",
      "Test Accuracy after 14 epochs: 45.50%\n",
      "[15, 10] Loss: 0.058\n",
      "Test Accuracy after 15 epochs: 47.00%\n",
      "[16, 10] Loss: 0.044\n",
      "Test Accuracy after 16 epochs: 46.50%\n",
      "[17, 10] Loss: 0.041\n",
      "Test Accuracy after 17 epochs: 43.50%\n",
      "[18, 10] Loss: 0.037\n",
      "Test Accuracy after 18 epochs: 46.00%\n",
      "[19, 10] Loss: 0.028\n",
      "Test Accuracy after 19 epochs: 46.00%\n",
      "[20, 10] Loss: 0.037\n",
      "Test Accuracy after 20 epochs: 46.00%\n",
      "[21, 10] Loss: 0.024\n",
      "Test Accuracy after 21 epochs: 45.00%\n",
      "[22, 10] Loss: 0.027\n",
      "Test Accuracy after 22 epochs: 45.00%\n",
      "[23, 10] Loss: 0.024\n",
      "Test Accuracy after 23 epochs: 45.00%\n",
      "[24, 10] Loss: 0.024\n",
      "Test Accuracy after 24 epochs: 45.50%\n",
      "[25, 10] Loss: 0.022\n",
      "Test Accuracy after 25 epochs: 46.00%\n",
      "[26, 10] Loss: 0.018\n",
      "Test Accuracy after 26 epochs: 46.00%\n",
      "[27, 10] Loss: 0.022\n",
      "Test Accuracy after 27 epochs: 47.00%\n",
      "[28, 10] Loss: 0.017\n",
      "Test Accuracy after 28 epochs: 46.00%\n",
      "[29, 10] Loss: 0.022\n",
      "Test Accuracy after 29 epochs: 45.00%\n",
      "[30, 10] Loss: 0.019\n",
      "Test Accuracy after 30 epochs: 42.50%\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your neural network\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "# Define the loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)\n",
    "\n",
    "# Set the number of training epochs\n",
    "num_epochs = 30\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:  # Print every 10 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] Loss: {running_loss / 10:.3f}\")\n",
    "            running_loss = 0.0\n",
    "            # Evaluate the model on the test dataset and calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in test_loader:\n",
    "                    images, labels = data\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            test_accuracy = 100 * correct / total\n",
    "            print(f\"Test Accuracy after {epoch + 1} epochs: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training finished\")\n",
    "\n",
    "# Save the trained model if desired\n",
    "# torch.save(net.state_dict(), \"my_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test dataset: 36.50%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Get the predicted class (the one with the highest probability)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update the total and correct counts\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test dataset: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
