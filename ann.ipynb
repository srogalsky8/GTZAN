{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "img_x_size = int(335)\n",
    "img_y_size = int(218)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(img_x_size * img_y_size * 3, 120)  # Flatten the input\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # Output layer with 10 units for 10 genres\n",
    "\n",
    "    def forward(self, x):\n",
    "        # # Max pooling over a (2, 2) window\n",
    "        # x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # # If the size is a square, you can specify with a single number\n",
    "        # x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = x.view(-1, 3 * img_x_size * img_y_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def custom_transform(image):\n",
    "    # Crop the image to the desired region of interest (ROI)\n",
    "    image = image.crop((55, 35, 390, 253))\n",
    "    # Convert the cropped image to a PyTorch tensor\n",
    "    return transforms.ToTensor()(image)\n",
    "\n",
    "# Define your data transformation (without resizing)\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Lambda(custom_transform),  # Apply the custom transformation\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "class CustomImageDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(CustomImageDataset, self).__init__(root=root, transform=transform)\n",
    "\n",
    "# Define the path to your data folder\n",
    "data_dir = 'data/images_original'\n",
    "\n",
    "# Create an instance of your custom dataset\n",
    "custom_dataset = CustomImageDataset(root=data_dir, transform=data_transform)\n",
    "\n",
    "# Calculate the size of the training and testing sets\n",
    "total_size = len(custom_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size])\n",
    "batch_size = 64  # You can adjust this batch size as needed\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape - Images: torch.Size([64, 3, 218, 335])\n",
      "Batch shape - Labels: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Get a batch of data from the training loader\n",
    "data_iterator = iter(train_loader)\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "# Check the shape of the batch\n",
    "print(\"Batch shape - Images:\", images.shape)\n",
    "print(\"Batch shape - Labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10] Loss: 2.290\n",
      "[2, 10] Loss: 2.243\n",
      "[3, 10] Loss: 2.158\n",
      "[4, 10] Loss: 2.062\n",
      "[5, 10] Loss: 1.949\n",
      "[6, 10] Loss: 1.862\n",
      "[7, 10] Loss: 1.763\n",
      "[8, 10] Loss: 1.659\n",
      "[9, 10] Loss: 1.587\n",
      "[10, 10] Loss: 1.474\n",
      "[11, 10] Loss: 1.384\n",
      "[12, 10] Loss: 1.279\n",
      "[13, 10] Loss: 1.189\n",
      "[14, 10] Loss: 1.099\n",
      "[15, 10] Loss: 1.016\n",
      "[16, 10] Loss: 0.927\n",
      "[17, 10] Loss: 0.850\n",
      "[18, 10] Loss: 0.748\n",
      "[19, 10] Loss: 0.689\n",
      "[20, 10] Loss: 0.608\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your neural network\n",
    "net = Net()\n",
    "\n",
    "# Define the loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set the number of training epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:  # Print every 10 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] Loss: {running_loss / 10:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Training finished\")\n",
    "\n",
    "# Save the trained model if desired\n",
    "# torch.save(net.state_dict(), \"my_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test dataset: 51.50%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Get the predicted class (the one with the highest probability)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update the total and correct counts\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test dataset: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
