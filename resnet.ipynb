{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    device = torch.device('cpu')\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "# Basic block for ResNet\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet model\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False)  # 1 input channel\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[1], stride=2)\n",
    "        self.linear = nn.Linear(17920 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 109, 167])\n",
      "Number of channels: 1\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "resize_scale = 0.5\n",
    "\n",
    "def custom_transform(image):\n",
    "    # Crop the image to the desired region of interest (ROI)\n",
    "    image = image.crop((55, 35, 390, 253))\n",
    "    # Convert the cropped image to a PyTorch tensor\n",
    "    return transforms.ToTensor()(image)\n",
    "\n",
    "def load_data(resize_images = False):\n",
    "    # Define your data transformation (without resizing)\n",
    "    transforms_list = []\n",
    "    transforms_list.append(transforms.Grayscale(num_output_channels=1))\n",
    "    transforms_list.append(transforms.Lambda(custom_transform))  # Apply the custom transformation\n",
    "    if resize_images:\n",
    "        transforms_list.append(transforms.Resize((int(218*resize_scale), int(335*resize_scale))))\n",
    "    transforms_list.append(transforms.Normalize((0.5,), (0.5,)))  # Normalize to [-1, 1]\n",
    "    data_transform = transforms.Compose(transforms_list)\n",
    "\n",
    "    class CustomImageDataset(datasets.ImageFolder):\n",
    "        def __init__(self, root, transform=None):\n",
    "            super(CustomImageDataset, self).__init__(root=root, transform=transform)\n",
    "\n",
    "    # Define the path to your data folder\n",
    "    data_dir = 'data/images_original'\n",
    "\n",
    "    # Create an instance of your custom dataset\n",
    "    custom_dataset = CustomImageDataset(root=data_dir, transform=data_transform)\n",
    "\n",
    "    # Calculate the size of the training and testing sets\n",
    "    total_size = len(custom_dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    test_size = total_size - train_size\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size])\n",
    "    batch_size = 64  # You can adjust this batch size as needed\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_data(resize_images=True)\n",
    "\n",
    "# Get a batch of data from the training loader\n",
    "data_iterator = iter(train_loader)\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "print(\"Image shape:\", images[0].shape)\n",
    "num_channels = images[0].shape[0]  # The number of channels in the image\n",
    "print(\"Number of channels:\", num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 39.693 | Accuracy: 20.50%\n",
      "Epoch 2 | Loss: 32.555 | Accuracy: 29.50%\n",
      "Epoch 3 | Loss: 25.801 | Accuracy: 42.50%\n",
      "Epoch 4 | Loss: 17.750 | Accuracy: 46.50%\n",
      "Epoch 5 | Loss: 12.179 | Accuracy: 58.00%\n",
      "Epoch 6 | Loss: 8.784 | Accuracy: 53.00%\n",
      "Epoch 7 | Loss: 7.376 | Accuracy: 65.50%\n",
      "Epoch 8 | Loss: 5.573 | Accuracy: 57.50%\n",
      "Epoch 9 | Loss: 4.812 | Accuracy: 57.50%\n",
      "Epoch 10 | Loss: 3.982 | Accuracy: 62.50%\n",
      "Epoch 11 | Loss: 2.495 | Accuracy: 65.00%\n",
      "Epoch 12 | Loss: 1.960 | Accuracy: 65.50%\n",
      "Epoch 13 | Loss: 1.368 | Accuracy: 63.00%\n",
      "Epoch 14 | Loss: 1.177 | Accuracy: 69.00%\n",
      "Epoch 15 | Loss: 0.924 | Accuracy: 66.50%\n",
      "Epoch 16 | Loss: 0.800 | Accuracy: 67.00%\n",
      "Epoch 17 | Loss: 0.617 | Accuracy: 69.00%\n",
      "Epoch 18 | Loss: 0.535 | Accuracy: 68.50%\n",
      "Epoch 19 | Loss: 0.580 | Accuracy: 68.50%\n",
      "Epoch 20 | Loss: 0.468 | Accuracy: 70.50%\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your neural network\n",
    "net = ResNet18()\n",
    "net.to(device)\n",
    "\n",
    "# Define the loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0005, momentum=0.9)\n",
    "\n",
    "# Set the number of training epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Evaluate the model on the test dataset and calculate accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch + 1} | Loss: {running_loss:.3f} | Accuracy: {test_accuracy:.2f}%\")\n",
    "    running_loss = 0.0\n",
    "\n",
    "print(\"Training finished\")\n",
    "\n",
    "# Save the trained model if desired\n",
    "# torch.save(net.state_dict(), \"my_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
