{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    device = torch.device('cpu')\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "img_x_size = int(335)\n",
    "img_y_size = int(218)\n",
    "num_channels = 1\n",
    "input_size = img_x_size * img_y_size * num_channels\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        in1 = 1\n",
    "        out1 = 20\n",
    "        self.conv1 = nn.Conv2d(in1, out1, (5,5))\n",
    "        self.bn1 = nn.BatchNorm2d(out1)\n",
    "        # self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        out2 = 40\n",
    "        self.conv2 = nn.Conv2d(out1, out2, (5,5))\n",
    "        self.bn2 = nn.BatchNorm2d(out2)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        out3 = 80\n",
    "        self.conv3 = nn.Conv2d(out2, out3, (5,5))\n",
    "        self.bn3 = nn.BatchNorm2d(out3)\n",
    "        # self.mp3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(out3 * 101 * 159, 500)\n",
    "        self.fc2 = nn.Linear(500, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: try batchnorm vs max pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.mp1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.mp2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steven/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 218, 335])\n",
      "Number of channels: 1\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "resize_scale = 0.75\n",
    "\n",
    "def custom_transform(image):\n",
    "    # Crop the image to the desired region of interest (ROI)\n",
    "    image = image.crop((55, 35, 390, 253))\n",
    "    # Convert the cropped image to a PyTorch tensor\n",
    "    return transforms.ToTensor()(image)\n",
    "\n",
    "def load_data(resize_images = False):\n",
    "    # Define your data transformation (without resizing)\n",
    "    transforms_list = []\n",
    "    transforms_list.append(transforms.Grayscale(num_output_channels=1))\n",
    "    transforms_list.append(transforms.Lambda(custom_transform))  # Apply the custom transformation\n",
    "    if resize_images:\n",
    "        transforms_list.append(transforms.Resize((int(218*resize_scale), int(335*resize_scale))))\n",
    "    transforms_list.append(transforms.Normalize((0.5,), (0.5,)))  # Normalize to [-1, 1]\n",
    "    data_transform = transforms.Compose(transforms_list)\n",
    "\n",
    "    class CustomImageDataset(datasets.ImageFolder):\n",
    "        def __init__(self, root, transform=None):\n",
    "            super(CustomImageDataset, self).__init__(root=root, transform=transform)\n",
    "\n",
    "    # Define the path to your data folder\n",
    "    data_dir = 'data/images_original'\n",
    "\n",
    "    # Create an instance of your custom dataset\n",
    "    custom_dataset = CustomImageDataset(root=data_dir, transform=data_transform)\n",
    "\n",
    "    # Calculate the size of the training and testing sets\n",
    "    total_size = len(custom_dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    test_size = total_size - train_size\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size])\n",
    "    batch_size = 10  # You can adjust this batch size as needed\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_data(resize_images=False)\n",
    "\n",
    "# Get a batch of data from the training loader\n",
    "data_iterator = iter(train_loader)\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "print(\"Image shape:\", images[0].shape)\n",
    "num_channels = images[0].shape[0]  # The number of channels in the image\n",
    "print(\"Number of channels:\", num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 162.728 | Accuracy: 25.00%\n",
      "Epoch 2 | Loss: 110.603 | Accuracy: 41.50%\n",
      "Epoch 3 | Loss: 63.930 | Accuracy: 47.00%\n",
      "Epoch 4 | Loss: 22.372 | Accuracy: 58.50%\n",
      "Epoch 5 | Loss: 7.729 | Accuracy: 51.00%\n",
      "Epoch 6 | Loss: 2.949 | Accuracy: 49.50%\n",
      "Epoch 7 | Loss: 2.932 | Accuracy: 54.50%\n",
      "Epoch 8 | Loss: 0.829 | Accuracy: 55.50%\n",
      "Epoch 9 | Loss: 0.094 | Accuracy: 55.50%\n",
      "Epoch 10 | Loss: 0.053 | Accuracy: 56.00%\n",
      "Epoch 11 | Loss: 0.038 | Accuracy: 56.00%\n",
      "Epoch 12 | Loss: 0.035 | Accuracy: 57.50%\n",
      "Epoch 13 | Loss: 0.037 | Accuracy: 57.00%\n",
      "Epoch 14 | Loss: 0.031 | Accuracy: 57.50%\n",
      "Epoch 15 | Loss: 0.024 | Accuracy: 58.00%\n",
      "Epoch 16 | Loss: 0.036 | Accuracy: 57.50%\n",
      "Epoch 17 | Loss: 0.025 | Accuracy: 59.00%\n",
      "Epoch 18 | Loss: 0.041 | Accuracy: 60.50%\n",
      "Epoch 19 | Loss: 0.027 | Accuracy: 59.00%\n",
      "Epoch 20 | Loss: 0.018 | Accuracy: 59.00%\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your neural network\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "# Define the loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set the number of training epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Evaluate the model on the test dataset and calculate accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch + 1} | Loss: {running_loss:.3f} | Accuracy: {test_accuracy:.2f}%\")\n",
    "    running_loss = 0.0\n",
    "\n",
    "print(\"Training finished\")\n",
    "\n",
    "# Save the trained model if desired\n",
    "# torch.save(net.state_dict(), \"my_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test dataset: 26.50%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Get the predicted class (the one with the highest probability)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update the total and correct counts\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test dataset: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 159\n"
     ]
    }
   ],
   "source": [
    "x1 = int(218)\n",
    "y1 = int(335)\n",
    "\n",
    "def reducepixels(num_pixels):\n",
    "    num_pixels = num_pixels - 4\n",
    "    # num_pixels = int(num_pixels / 2)\n",
    "    num_pixels = num_pixels - 4\n",
    "    num_pixels = int(num_pixels / 2)\n",
    "    num_pixels = num_pixels - 4\n",
    "    return num_pixels\n",
    "\n",
    "print(reducepixels(x1), reducepixels(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
